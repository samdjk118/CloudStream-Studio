from google.cloud import storage
from google.cloud.exceptions import NotFound, GoogleCloudError
from typing import List, Optional, BinaryIO, Union
import logging
import os
from pathlib import Path
from .gcs_auth import get_storage_client

logger = logging.getLogger(__name__)


class GCSManager:
    """Google Cloud Storage ç®¡ç†å™¨"""
    
    def __init__(self, bucket_name: str, project_id: str = None):
        """
        åˆå§‹åŒ– GCS ç®¡ç†å™¨
        
        Args:
            bucket_name: Bucket åç¨±
            project_id: é …ç›® ID (å¯é¸)
        """
        self.bucket_name = bucket_name
        self.project_id = project_id or os.getenv('GCP_PROJECT_ID')
        self.client = get_storage_client(self.project_id)
        self.bucket = self.client.bucket(bucket_name)
        
        logger.info(f"ğŸ“¦ GCS Manager åˆå§‹åŒ–: {bucket_name}")
    
    def list_files(self, prefix: str = None, max_results: int = None) -> List[dict]:
        """
        åˆ—å‡ºæ–‡ä»¶
        
        Args:
            prefix: æ–‡ä»¶å‰ç¶´éæ¿¾
            max_results: æœ€å¤§çµæœæ•¸
        
        Returns:
            List[dict]: æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
        """
        try:
            blobs = self.bucket.list_blobs(prefix=prefix, max_results=max_results)
            
            files = []
            for blob in blobs:
                files.append({
                    "name": blob.name,
                    "size": blob.size,
                    "content_type": blob.content_type,
                    "created": blob.time_created.isoformat() if blob.time_created else None,
                    "updated": blob.updated.isoformat() if blob.updated else None,
                    "url": f"gs://{self.bucket_name}/{blob.name}",
                    "public_url": blob.public_url if hasattr(blob, 'public_url') else None
                })
            
            logger.info(f"ğŸ“‹ åˆ—å‡º {len(files)} å€‹æ–‡ä»¶")
            return files
            
        except Exception as e:
            logger.error(f"âŒ åˆ—å‡ºæ–‡ä»¶å¤±æ•—: {e}")
            raise
    
    def upload_file(
        self,
        source: Union[BinaryIO, bytes, str],
        destination_name: str,
        content_type: str = None,
        make_public: bool = False
    ) -> dict:
        """
        ä¸Šå‚³æ–‡ä»¶
        
        Args:
            source: æ–‡ä»¶ä¾†æº (æ–‡ä»¶å°è±¡ã€å­—ç¯€æˆ–æ–‡ä»¶è·¯å¾‘)
            destination_name: ç›®æ¨™æ–‡ä»¶å
            content_type: å…§å®¹é¡å‹
            make_public: æ˜¯å¦è¨­ç‚ºå…¬é–‹
        
        Returns:
            dict: ä¸Šå‚³çµæœ
        """
        try:
            blob = self.bucket.blob(destination_name)
            
            # æ ¹æ“šä¾†æºé¡å‹ä¸Šå‚³
            if isinstance(source, bytes):
                blob.upload_from_string(source, content_type=content_type)
            elif isinstance(source, str):
                # å‡è¨­æ˜¯æ–‡ä»¶è·¯å¾‘
                blob.upload_from_filename(source, content_type=content_type)
            else:
                # å‡è¨­æ˜¯æ–‡ä»¶å°è±¡
                blob.upload_from_file(source, content_type=content_type)
            
            # è¨­ç‚ºå…¬é–‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if make_public:
                blob.make_public()
            
            logger.info(f"âœ… ä¸Šå‚³æˆåŠŸ: {destination_name}")
            
            return {
                "success": True,
                "filename": destination_name,
                "size": blob.size,
                "content_type": blob.content_type,
                "url": f"gs://{self.bucket_name}/{destination_name}",
                "public_url": blob.public_url if make_public else None
            }
            
        except Exception as e:
            logger.error(f"âŒ ä¸Šå‚³å¤±æ•—: {e}")
            raise
    
    def download_file(self, filename: str, destination: str = None) -> Optional[bytes]:
        """
        ä¸‹è¼‰æ–‡ä»¶
        
        Args:
            filename: æ–‡ä»¶å
            destination: æœ¬åœ°ä¿å­˜è·¯å¾‘ (å¯é¸)
        
        Returns:
            bytes: æ–‡ä»¶å…§å®¹ (å¦‚æœæ²’æœ‰æŒ‡å®š destination)
            None: å¦‚æœæŒ‡å®šäº† destination
        """
        try:
            blob = self.bucket.blob(filename)
            
            if not blob.exists():
                raise NotFound(f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            
            if destination:
                # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
                blob.download_to_filename(destination)
                logger.info(f"âœ… ä¸‹è¼‰æˆåŠŸ: {filename} -> {destination}")
                return None
            else:
                # è¿”å›å­—ç¯€å…§å®¹
                content = blob.download_as_bytes()
                logger.info(f"âœ… ä¸‹è¼‰æˆåŠŸ: {filename} ({len(content)} bytes)")
                return content
                
        except NotFound:
            logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            raise
        except Exception as e:
            logger.error(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
            raise
    
    def download_bytes(self, filename: str, start: int = None, end: int = None) -> bytes:
        """
        ä¸‹è¼‰æ–‡ä»¶çš„å­—ç¯€ç¯„åœ
        
        Args:
            filename: æ–‡ä»¶å
            start: èµ·å§‹å­—ç¯€ä½ç½® (å¯é¸)
            end: çµæŸå­—ç¯€ä½ç½® (å¯é¸)
        
        Returns:
            bytes: æ–‡ä»¶å…§å®¹
        """
        try:
            blob = self.bucket.blob(filename)
            
            if not blob.exists():
                raise NotFound(f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            
            if start is not None and end is not None:
                # ä¸‹è¼‰æŒ‡å®šç¯„åœ
                logger.info(f"ğŸ“¥ ä¸‹è¼‰ç¯„åœ: {filename} [{start}-{end}]")
                return blob.download_as_bytes(start=start, end=end)
            else:
                # ä¸‹è¼‰æ•´å€‹æ–‡ä»¶
                logger.info(f"ğŸ“¥ ä¸‹è¼‰å®Œæ•´æ–‡ä»¶: {filename}")
                return blob.download_as_bytes()
                
        except NotFound:
            logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            raise
        except Exception as e:
            logger.error(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
            raise
    
    def upload_bytes(self, filename: str, data: bytes, content_type: str = None):
        """
        ä¸Šå‚³å­—ç¯€æ•¸æ“š
        
        Args:
            filename: ç›®æ¨™æ–‡ä»¶å
            data: å­—ç¯€æ•¸æ“š
            content_type: å…§å®¹é¡å‹
        """
        try:
            blob = self.bucket.blob(filename)
            blob.upload_from_string(data, content_type=content_type)
            logger.info(f"âœ… ä¸Šå‚³æˆåŠŸ: {filename} ({len(data)} bytes)")
        except Exception as e:
            logger.error(f"âŒ ä¸Šå‚³å¤±æ•—: {e}")
            raise
    
    def get_blob(self, filename: str):
        """
        ç²å– Blob å°è±¡
        
        Args:
            filename: æ–‡ä»¶å
        
        Returns:
            Blob: Google Cloud Storage Blob å°è±¡
        """
        return self.bucket.blob(filename)
    
    def delete_file(self, filename: str) -> bool:
        """
        åˆªé™¤æ–‡ä»¶
        
        Args:
            filename: æ–‡ä»¶å
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            blob = self.bucket.blob(filename)
            
            if not blob.exists():
                raise NotFound(f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            
            blob.delete()
            logger.info(f"ğŸ—‘ï¸  åˆªé™¤æˆåŠŸ: {filename}")
            return True
            
        except NotFound:
            logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            raise
        except Exception as e:
            logger.error(f"âŒ åˆªé™¤å¤±æ•—: {e}")
            raise
    
    def file_exists(self, filename: str) -> bool:
        """
        æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        
        Args:
            filename: æ–‡ä»¶å
        
        Returns:
            bool: æ˜¯å¦å­˜åœ¨
        """
        try:
            blob = self.bucket.blob(filename)
            return blob.exists()
        except Exception as e:
            logger.error(f"âŒ æª¢æŸ¥æ–‡ä»¶å¤±æ•—: {e}")
            return False
    
    def get_file_info(self, filename: str) -> dict:
        """
        ç²å–æ–‡ä»¶ä¿¡æ¯
        
        Args:
            filename: æ–‡ä»¶å
        
        Returns:
            dict: æ–‡ä»¶ä¿¡æ¯
        """
        try:
            blob = self.bucket.blob(filename)
            
            if not blob.exists():
                raise NotFound(f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            
            blob.reload()
            
            return {
                "name": blob.name,
                "size": blob.size,
                "content_type": blob.content_type,
                "created": blob.time_created.isoformat() if blob.time_created else None,
                "updated": blob.updated.isoformat() if blob.updated else None,
                "md5_hash": blob.md5_hash,
                "url": f"gs://{self.bucket_name}/{blob.name}",
                "public_url": blob.public_url if hasattr(blob, 'public_url') else None
            }
            
        except NotFound:
            logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            raise
        except Exception as e:
            logger.error(f"âŒ ç²å–æ–‡ä»¶ä¿¡æ¯å¤±æ•—: {e}")
            raise
    
    def copy_file(self, source_name: str, destination_name: str) -> dict:
        """
        è¤‡è£½æ–‡ä»¶
        
        Args:
            source_name: æºæ–‡ä»¶å
            destination_name: ç›®æ¨™æ–‡ä»¶å
        
        Returns:
            dict: è¤‡è£½çµæœ
        """
        try:
            source_blob = self.bucket.blob(source_name)
            
            if not source_blob.exists():
                raise NotFound(f"æºæ–‡ä»¶ä¸å­˜åœ¨: {source_name}")
            
            # è¤‡è£½åˆ°åŒä¸€å€‹ bucket
            destination_blob = self.bucket.copy_blob(
                source_blob,
                self.bucket,
                destination_name
            )
            
            logger.info(f"âœ… è¤‡è£½æˆåŠŸ: {source_name} -> {destination_name}")
            
            return {
                "success": True,
                "source": source_name,
                "destination": destination_name,
                "size": destination_blob.size
            }
            
        except NotFound:
            logger.error(f"âŒ æºæ–‡ä»¶ä¸å­˜åœ¨: {source_name}")
            raise
        except Exception as e:
            logger.error(f"âŒ è¤‡è£½å¤±æ•—: {e}")
            raise
    
    def move_file(self, source_name: str, destination_name: str) -> dict:
        """
        ç§»å‹•æ–‡ä»¶ï¼ˆè¤‡è£½å¾Œåˆªé™¤æºæ–‡ä»¶ï¼‰
        
        Args:
            source_name: æºæ–‡ä»¶å
            destination_name: ç›®æ¨™æ–‡ä»¶å
        
        Returns:
            dict: ç§»å‹•çµæœ
        """
        try:
            # å…ˆè¤‡è£½
            result = self.copy_file(source_name, destination_name)
            
            # å†åˆªé™¤æºæ–‡ä»¶
            self.delete_file(source_name)
            
            logger.info(f"âœ… ç§»å‹•æˆåŠŸ: {source_name} -> {destination_name}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ç§»å‹•å¤±æ•—: {e}")
            raise
    
    def get_signed_url(
        self,
        filename: str,
        expiration: int = 3600,
        method: str = 'GET'
    ) -> str:
        """
        ç”Ÿæˆç°½å URL
        
        Args:
            filename: æ–‡ä»¶å
            expiration: éæœŸæ™‚é–“ï¼ˆç§’ï¼‰
            method: HTTP æ–¹æ³•
        
        Returns:
            str: ç°½å URL
        """
        try:
            blob = self.bucket.blob(filename)
            
            from datetime import timedelta
            url = blob.generate_signed_url(
                expiration=timedelta(seconds=expiration),
                method=method
            )
            
            logger.info(f"âœ… ç”Ÿæˆç°½å URL: {filename}")
            return url
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆç°½å URL å¤±æ•—: {e}")
            raise


# ä¾¿æ·å‡½æ•¸
def create_gcs_manager(bucket_name: str = None, project_id: str = None) -> GCSManager:
    """
    å‰µå»º GCS ç®¡ç†å™¨
    
    Args:
        bucket_name: Bucket åç¨±ï¼ˆå¾ç’°å¢ƒè®Šé‡è®€å–å¦‚æœæœªæä¾›ï¼‰
        project_id: é …ç›® IDï¼ˆå¾ç’°å¢ƒè®Šé‡è®€å–å¦‚æœæœªæä¾›ï¼‰
    
    Returns:
        GCSManager: GCS ç®¡ç†å™¨å¯¦ä¾‹
    """
    bucket = bucket_name or os.getenv('GCS_BUCKET_NAME')
    if not bucket:
        raise ValueError("å¿…é ˆæä¾› bucket_name æˆ–è¨­ç½® GCS_BUCKET_NAME ç’°å¢ƒè®Šé‡")
    
    return GCSManager(bucket, project_id)
